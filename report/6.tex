\subsection{
    Step 6: \texttt{ns} and \texttt{sigma}
}

Step 6 corresponds to the code seen in \autoref{fut:kernel6}.

\begin{figure}[H]
    \centering
    \ehaskell[firstline=165,lastline=178]{../src/fut-handout/bfast-distrib.fut}
    \caption{Futhark function for calculating \texttt{nss} and \texttt{sigmas}.}
    \label{fut:kernel6}
\end{figure}

In our translation, seen in \autoref{cuda:kernel6},
we reuse shared memory for separate tasks on line 37 by aliasing a pointer to
it. 

We do this based on the rule of thumb attributed to Aske Dorge in \cite[p.
29]{pmphL5}, which states that:
\enquote{
    \textit{
        \approx 8 words of shared memory per thread does not degrade performance.
}}

If we use two separately allocated arrays of 1024 words for \(n\approx228\)
giving around \(\nicefrac{2048}{228} = 8.98\) words, experiments show that
the kernel's running time goes from 2144.56 µs to
2508.82 µs equaling a slowdown close of 17\% and confirming the rule.

When we reuse the memory, we get a factor of \(\nicefrac{1024}{228} = 4.49\)
words per thread. We make sure to never use the memory location for more than
one purpose at a time.

\begin{figure}[H]
    \centering
    \ecuda[firstline=2,lastline=49]{../src/kernels/bfast_step_6.cu}
    \caption{CUDA kernel for calculating \texttt{nss} and \texttt{sigmas}.}
    \label{cuda:kernel6}
\end{figure}

The launch code is seen in \autoref{cuda:orch6}.

\begin{figure}[H]
    \centering
    \ecuda[firstline=51,lastline=62]{../src/kernels/bfast_step_6.cu}
    \caption{CUDA orchestrating code for kernel 6.}
    \label{cuda:orch6}
\end{figure}

