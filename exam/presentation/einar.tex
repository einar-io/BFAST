\section{Part one}

\begin{frame}[fragile]{Overview}
\begin{enumerate}
    \item Baseline measurements
    \item \texttt{scan} and memory accesses
    \item Occupancy and Aske Dorge's rule of thumb for shared
        memory%\texttt{bfast\_step\_6} 
    \item (extra) Partition \texttt{bfast\_step\_5}
\end{enumerate}
    \pause
Questions are appreciated during and after the presentation :)
\end{frame}


\begin{frame}[fragile]{Baseline}

The baseline: \mint{bash}|make benchmark-naive|

\end{frame}

\begin{frame}[fragile]{Baseline}
    \centering
    \begin{minted}{text}
bfast-naive (all times are an average of 500 runs):

bfast_step_1_run         12.25 µs
transpose_X              11.86 µs
bfast_step_2_run      23678.14 µs
bfast_step_3_run       2648.65 µs
transpose_Y            1212.03 µs
bfast_step_4a_run      1265.11 µs
untranspose_beta0        77.18 µs
bfast_step_4b_run       507.25 µs
transpose_beta           75.39 µs
bfast_step_4c_run      3981.45 µs
untranspose_y_preds    1209.31 µs
bfast_step_5_run       2910.24 µs
bfast_step_6_run       2475.36 µs
bfast_step_7a_run       480.90 µs
bfast_step_7b_run        11.07 µs
bfast_step_8_run       6869.04 µs


Total runtime         47425.22 µs
\end{minted}

\end{frame}

\begin{frame}[fragile]{Baseline}
%
%The missing baseline: \mint{bash}|make benchmark-naive|
%    \centering

    \begin{minted}[escapeinside=||]{text}
bfast-naive (average of 500 runs):

bfast_step_1_run         12.25 µs
transpose_X              11.86 µs
bfast_step_2_run     |\colorbox{teal}{23678.14 µs}|
bfast_step_3_run       2648.65 µs
transpose_Y            1212.03 µs
bfast_step_4a_run      1265.11 µs
untranspose_beta0        77.18 µs
bfast_step_4b_run       507.25 µs
transpose_beta           75.39 µs
bfast_step_4c_run     |\colorbox{teal}{3981.45 µs}|
untranspose_y_preds    1209.31 µs
bfast_step_5_run       2910.24 µs
bfast_step_6_run       2475.36 µs
bfast_step_7a_run       480.90 µs
bfast_step_7b_run        11.07 µs
bfast_step_8_run      |\colorbox{teal}{6869.04 µs}|


Total runtime         47425.22 µs
\end{minted}

\end{frame}

\begin{frame}[fragile]{Baseline}
%
%The missing baseline: \mint{bash}|make benchmark-naive|
%    \centering

\begin{minipage}{.5\textwidth}
    \begin{minted}[escapeinside=||]{text}
bfast-naive (average of 500 runs):

bfast_step_1_run         12.25 µs
transpose_X              11.86 µs
bfast_step_2_run     |\colorbox{teal}{23678.14 µs}|
bfast_step_3_run       2648.65 µs
transpose_Y            1212.03 µs
bfast_step_4a_run      1265.11 µs
untranspose_beta0        77.18 µs
bfast_step_4b_run       507.25 µs
transpose_beta           75.39 µs
bfast_step_4c_run     |\colorbox{teal}{3981.45 µs}|
untranspose_y_preds    1209.31 µs
bfast_step_5_run       2910.24 µs
bfast_step_6_run       2475.36 µs
bfast_step_7a_run       480.90 µs
bfast_step_7b_run        11.07 µs
bfast_step_8_run      |\colorbox{teal}{6869.04 µs}|


Total runtime         47425.22 µs
\end{minted}
\begin{center}
Baseline implementation
\end{center}
\end{minipage}%
%
\begin{minipage}{.55\textwidth}
%\pause
%
%We need to keep this in mind to appreciate the optimized kernels:
%
%\end{frame}
%
%\begin{frame}[fragile]{Optimizations}
%
    %..the optimized kernels: \mint{bash}|make benchmark|
%
%\centering
%
\begin{minted}{text}
bfast-opt (average of 500 runs):

bfast_step_1_run             11.31 µs
transpose_X                  10.85 µs
transpose_Y                1218.72 µs
bfast_step_2_tiled_run     2684.43 µs
bfast_step_3_run           2611.89 µs
bfast_step_4a_tiled_run     710.43 µs
untranspose_beta0            76.11 µs
bfast_step_4b_run           500.99 µs
bfast_step_4c_tiled_run    1004.92 µs
bfast_step_5_run           2878.94 µs
bfast_step_6_reuse_run     1981.48 µs
bfast_step_7a_run           474.37 µs
bfast_step_7b_run            10.18 µs
bfast_step_8_opt2_run      1721.84 µs


Total runtime             15896.45 µs
\end{minted}
\begin{center}
Optimized
\end{center}
%
%
\end{minipage}
%bfast-opt (all times are an average of 500 runs):
%
%bfast_step_1_run             12.33 µs
%transpose_X                  11.74 µs
%transpose_Y                1226.57 µs
%bfast_step_2_tiled_run     2684.43 µs
%bfast_step_3_run           2609.89 µs
%bfast_step_4a_tiled_run     708.69 µs
%untranspose_beta0            76.95 µs
%bfast_step_4b_run           501.44 µs
%bfast_step_4c_tiled_run    1002.97 µs
%bfast_step_5_run           2878.34 µs
%bfast_step_6_reuse_run     1981.08 µs
%bfast_step_7a_run           474.89 µs
%bfast_step_7b_run            10.88 µs
%bfast_step_8_opt2_run      1722.23 µs
%
%
%Total runtime             15902.44 µs

\pause
Achieved by applying optimizations:
\(\frac{47425.22}{15896.45} \approx 2.98 \times \) speed-up.



\end{frame}



\section{\texttt{scan}} 

\begin{frame}[fragile]{\texttt{scaninc\_block\_add\_nowrite}}
\begin{minted}{cuda}
template <class T>
__device__ inline T scaninc_block_add_nowrite(volatile T *in)
{
  const unsigned int idx    = threadIdx.x;
  const unsigned int lane   = idx &  31;
  const unsigned int warpid = idx >> 5;

  T val = scaninc_warp_add(in); // warps execute in lockstep, no sync needed
  __syncthreads();

  if (lane == 31) { in[warpid] = val; }
  __syncthreads();

  if (warpid == 0) scaninc_warp_add(in);
  __syncthreads();

  if (warpid > 0) {
    val = in[warpid-1] + val;
  }

  return val; // Final value is not written to memory.
}
\end{minted}
\end{frame}

\begin{frame}[fragile]{\texttt{scan\_block\_add}}
    Thin wrapper in case we actually need the written array afterwards:
\begin{minted}{cuda}
template <class T>
__device__ inline void scaninc_block_add(volatile T *in)
{
  T val = scaninc_block_add_nowrite(in);
  __syncthreads();
  in[threadIdx.x] = val;
  __syncthreads();
}
\end{minted}

\pause Work and and depth are not improved, but this is about the constants.

\end{frame}


\section{\texttt{bfast\_step\_6}} 


\begin{frame}[fragile]{\texttt{scan\_block\_add\_nowrite} as \texttt{reduce}}

    Out of a total four usages two of them are in kernel 6:

    \begin{table}
        \centering
        \begin{tabular}{l r}
            
          \footnotesize  \textbf{Kernel} & \textbf{Average running time} \\ \hline
           \footnotesize \texttt{bfast\_step\_6\_reuse\_run} &     2135.66 µs \\
          \footnotesize  \texttt{bfast\_step\_6\_reuse\_run (\_nowrite)} & 1981.48 µs
        \end{tabular}
        \caption{Measurements are averages over 500 runs.}
        \label{tab:nowrite}
    \end{table}

\(\frac{2135.66}{1981.48}  \approx 1.08 \times \) speed-up.

\end{frame}


\begin{frame}[fragile]{CUDA}

\begin{minted}{cuda}
__global__ void bfast_step_6_reuse(float *Yh, float *y_errors, int *nss,
    float *sigmas, int n, int N, int k2p2)
{
  /* .. */
  extern __shared__ int num_valids[]; //sizeof(num_valid[]) == n * sizeof(float)
  num_valids[threadIdx.x] = !isnan(yh[threadIdx.x]);
  __syncthreads();
  int val_ns = scaninc_block_add_nowrite<int>(num_valids);
  int ns;
  if (threadIdx.x == n-1) {
    ns = val_ns;           // Naïve: int ns = num_valids[n - 1];
  }
  __syncthreads(); // necessary because shared memory is reused

  float *sigma_shared = (float *) num_valids; // Reuse ok.
  float val = threadIdx.x < ns ? y_error[threadIdx.x] : 0.0;
  val = val * val;
  sigma_shared[threadIdx.x] = val;
  __syncthreads();
  float val_sigma = scaninc_block_add_nowrite<float>(sigma_shared);

  if (threadIdx.x == n-1) { // Naïve: __shared__ float sigma_shared[1024];
    sigmas[blockIdx.x] = __fsqrt_rd(val_sigma / ((float)(ns - k2p2))); // Intrinsic
    nss[blockIdx.x] = ns;
  }
}
\end{minted}
\end{frame}

\begin{frame}[fragile]{Aske Dorge's rule of thumb}

\footnotesize \enquote{
    \textit{
       8 words of shared memory per thread does not degrade performance. 
    }
}
\pause

\begin{itemize}
    \item \(\nicefrac{2\cdot 1024}{228} = 8.98\) words per thread in block
    \item \(\nicefrac{1024}{228} = 4.49\) words per thread in block
\end{itemize}

\pause
Wordsize: \mint{cuda}|sizeof{int} == 4 == sizeof{float}| = 32 bits.


\end{frame}

\begin{frame}[fragile]{Impact}

    \begin{table}
        \centering
        \begin{tabular}{l r}
            \textbf{Kernel} & \textbf{Average running time} \\ \hline
          \footnotesize  \texttt{bfast\_step\_6\_run} &    2508.82  µs \\
          \footnotesize   \texttt{bfast\_step\_6\_reuse\_run}  & 2144.56  µs \\
          \footnotesize \texttt{bfast\_step\_6\_reuse\_run} (reuse,nowrite,dyn) &  1981.48 µs
        \end{tabular}
        \caption{Measurements are averages over 500 runs.}
       \label{tab:noreuse}
    \end{table}

    \pause

    Speed-up: \approx 1.17 \times.
        
    %\pause
    
    %\mint{cuda}|bfast_step_6_reuse<<<m, n, n * sizeof(float)>>>|

\end{frame}



\begin{frame}[fragile]{Occupancy}

    \begin{description}
        \item [Occupancy] When each block uses more than their fair share of
            total available shared memory, less blocks can be scheduled to run
            concurrently on the SMs. This means that some SMs are fully utilized, which \textit{is} low occupancy.
        \item [Memory usage] thus indirectly limits potential speed-up.
    \end{description}


    \pause

    If time allows \texttt{bfast\_step\_5}.
\end{frame}



\section{Partition in \texttt{bfast\_step\_5}} % Einar


%\begin{frame}[fragile]{Futhark}
%  -- Cosmin's tip for this bit: Assume N < 1024
%
%  ---------------------------------------------
%  -- 5. filter etc.                          --
%  ---------------------------------------------
%  -- Nss:        Nss[i] where 0<=i<m is the number of valid (non-NaN) entries
%  --             for time series i
%  -- y_errors:   y_errors[i] where 0<=i<m is an array of error values for time
%  --             series i, partitioned such that valid (non-NaN) entries come
%  --             before invalid (NaN) entries.
%  -- vald_indss: vald_indss[i] where 0<=i<m is an array of indices indicating
%  --             the original positions of the elements in y_errors[i], i.e.,
%  --             before partitioning.
%\begin{minted}{haskell}
%let (Nss, y_errors, val_indss) =
%unsafe ( intrinsics.opaque <| unzip3 <|
%  map2 (\y y_pred ->
%    let y_error_all = zip y y_pred |>
%      map (\(ye,yep) -> if !(f32.isnan ye) 
%                        then ye-yep 
%                        else f32.nan )
%    let (tups, Ns) = zip2 y_error_all (iota N) |>
%      partitionCos (\(ye,_) -> !(f32.isnan ye)) (0.0, 0)
%    let (y_error, val_inds) = unzip tups
%    in  (Ns, y_error, val_inds)
%      ) images y_preds )
%\end{minted}

%\end{frame}

\begin{frame}[fragile]{\texttt{partitionCos}}

    \begin{minted}{haskell}
let partitionCos [n] 't
           (p : (t -> bool))
           (dummy : t)
           (arr : [n]t) : ([n]t, i32) =
  let cs  = map p arr
  let tfs = map (\f -> if f then 1 else 0) cs
  let ffs = map (\f -> if f then 0 else 1) cs
  let isT = scan (+) 0 tfs
  let isF0= scan (+) 0 ffs

  let i   = last isT
  let isF = map (+i) isF0
  let inds= map3 (\c iT iF ->
                    if c then iT-1
                         else iF-1
                 ) cs isT isF
  let r = scatter (replicate n dummy) inds arr
  in  (r, i)
  \end{minted}

  \pause

  The best way to optimize \texttt{scan} is not to call it.

\end{frame}


\begin{frame}[fragile]{Merge the \texttt{scan}s}
\begin{minted}{haskell}
  let isT = scan (+) 0 tfs
  let isF0= scan (+) 0 ffs
\end{minted}

  \begin{enumerate}
      \item Use a tuple \( (\sum_0^i p(arr[i]), \sum_0^i !p(arr[i]) ) \)
      \item Use the invariant: \( i = \sum_0^i p(arr[i]) + \sum_0^i !p(arr[i]) \)
  \end{enumerate}
  \pause

  \[  \sum_0^i !p(arr[i]) = i - \sum_0^i p(arr[i]) \]

\end{frame}


\begin{frame}[fragile]{Merge the \texttt{scan}s}
\begin{minted}{cuda}
__global__ void bfast_step_5(float *Y, float *y_preds, int *Nss,
    float *y_errors, int *val_indss, int N)
{
  /* .. */
  // Partition
  extern __shared__ int num_valids[]; // N
  num_valids[threadIdx.x] = !isnan(err);
  __syncthreads();
  scaninc_block_add<int>(num_valids);
  int i = num_valids[N - 1];

  unsigned int idx;
  if (!isnan(err)) {
    idx = num_valids[threadIdx.x] - 1;
  } else {
    idx = threadIdx.x - num_valids[threadIdx.x] + i; // i is the demarcation
  }

  y_error[idx] = err;
  val_inds[idx] = threadIdx.x;
  if (threadIdx.x == 0) {
    *Ns = i;
  }
}
\end{minted}
\end{frame}
